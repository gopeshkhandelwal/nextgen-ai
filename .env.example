# === OpenAI Configuration ===
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_API_BASE=https://api.openai.com/v1
OPENAI_MODEL=gpt-4

# === vLLM Configuration ===
VLLM_API_BASE=http://localhost:8000/v1
VLLM_MODEL=vllm-fork-with-hermes-2-pro-llama-3-8b
VLLM_MODEL_PATH=./resources/models/NousResearch/Hermes-2-Pro-Llama-3-8B
VLLM_MAX_TOKENS=512
VLLM_TEMPERATURE=0.3

# === General Configuration ===
MAX_TOKENS=4096
HUGGINGFACE_HUB_TOKEN=hf_token_here

# === OpenWeather Configuration ===
OPENWEATHER_API_KEY=your-openweather-api-key-here

# === IDC API Endpoints ===
IDC_API_POOLS=idc_pools_url
IDC_API_IMAGES=idc_machineimages_url
ITAC_PRODUCTS=idc_products_url
ITAC_API_TOKEN=your-idc-jwt-token-here

# === RAG Configuration ===
RAG_DOC_PATH=docs/grpc_api_guide.txt
RAG_INDEX_DIR=resources/vectorstore/faiss_index
RAG_EMBED_MODEL=./resources/models/minilm
RAG_SEMANTIC_WEIGHT=0.7
RAG_KEYWORD_WEIGHT=0.3
RAG_RETRIEVAL_K=5
RAG_CACHE_SIZE=15
RAG_ENABLE_RERANKER=true
RAG_RERANKER_MODEL=cross-encoder/ms-marco-MiniLM-L-12-v2
RAG_RERANK_CANDIDATE_MULTIPLIER=3

# === MCP Configuration ===
MCP_SOCKET_PATH=/tmp/mcp.sock

# === Memory Configuration ===
SHORT_TERM_MEMORY=3
LONG_TERM_MEMORY=7
LOW_CONFIDENCE_PHRASES=don't know,don't have,not sure,not certain,no info,no information,i'm sorry,can't help,check docs,unsure,not able to help,need the name,need to access,current conversation,don't see,can't find,not visible,missing,unclear,I'm sorry, but I don't have that information

# === Database Configuration ===
DB_NAME=db_name
DB_USER=db_user
DB_PASS=your-db-password
DB_HOST=db_host
DB_PORT=5432

# === Langfuse Configuration ===
LANGFUSE_PUBLIC_KEY=pk-lf-xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
LANGFUSE_SECRET_KEY=sk-lf-xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
LANGFUSE_HOST=http://localhost:3000
LANGFUSE_ENABLED=true